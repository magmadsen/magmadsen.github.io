# Takeaways from Natural Language Processing (NLP)

Natural Language Processing (NLP) is a highly relevant field that works with allowing computers to interact and understand human language. With the increasing focus and evoulution in deep learning, NLP has improved significantly and it has helped create aplications for machine translation, sentiment analysis and chatbots. In this post I will dive into the world of NLP and it's relevance in the fast.ai course. This blog post is highly based on the content presented in 10_nlp.ipynb notebook from the fastbook [^1].

[^1]:  10_nlp.ipynb notebook [link](https://github.com/fastai/fastbook/blob/master/10_nlp.ipynb)


## Text Preprocessing
Multiple steps are involved in pre-processing text in the fast.ai library.

### Word Tokenization with fast.ai
Tokenization is the process of splitting text into individual tokens, which can be words, subwords, or characters. fast.ai supports word-based and subword-based tokenization approaches [^1]. fast.ai procides the oppotunity to use different tokenizers from external library. Here's an example of using a tokenizer on the IMDb dataset:

```python
from fastai.text.all import *
path = untar_data(URLs.IMDB)
files = get_text_files(path, folders=['train', 'test', 'unsup'])
txt = files[0].open().read()

# Tokenization
tok = Tokenizer.from_folder(path)
tok.setup(files)
toks = tok(txt)
```
Where toks will contain the tokens of the text.

### Numericalization

Numericalization is the process of converting tokens into numerical representations. It works by making a vocabulary of all unique words and mapping each word to an index in the vocabulary.
It involves creating a vocabulary of unique words and mapping each word to a corresponding index. This allows for machine learning algorithms to process and analyze otherwise abstract text data. It can be done in the following way in the fast.ai library  [^1]:

```python
toks200 = txts[:200].map(tkn)
num = Numericalize()
num.setup(toks200)
coll_repr(num.vocab,20)
nums = num(toks)[:20]; nums
' '.join(num.vocab[o] for o in nums)
```

The next step involved putting the numerical representation in batches such that it can be used in a language model.

## Using DataBlocks
If one were to use DataBlocks instead the fast.ai library can handle the text processing automatically. Here is how to use it on the IMDB dataset:

```python
get_imdb = partial(get_text_files, folders=['train', 'test', 'unsup'])

dls_lm = DataBlock(
    blocks=TextBlock.from_folder(path, is_lm=True),
    get_items=get_imdb, splitter=RandomSplitter(0.1)
).dataloaders(path, path=path, bs=128, seq_len=80)
```

In this example the text data is read into a DataBlock using the TextBlock method. This class handles the tokenization and numericalization automatically in an optimized fasion. 

### Fitting a language model to the data
Once the data is saved in a DataBlock object it can easily be fitted to a model. In the following example it is used on the AWD_LTSM model which is an RNN.

```python
learn = language_model_learner(
    dls_lm, AWD_LSTM, drop_mult=0.3, 
    metrics=[accuracy, Perplexity()]).to_fp16()
```

### Fine tuning the model
The fitted model can be fine tuned with our data using the following command in the fast.ai library:

```python
learn.fit_one_cycle(1, 2e-2)
```
## Text generation from model
Once we have a trained model it can be used to generate new reviews for the IMDb dataset.

```python
TEXT = "I liked this movie because"
N_WORDS = 40
N_SENTENCES = 2
preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) 
         for _ in range(N_SENTENCES)]
```
In this case it is used to predict the comming words by initializing it with some text.
